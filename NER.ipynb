{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5a0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115be59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod\\AppData\\Local\\Temp\\ipykernel_17048\\440594826.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "def process_tag(tag):\n",
    "    tag = [t.split(\"-\")[1] if t != 'O' else t for t in tag]\n",
    "    tag = [\"<s>\"] + tag\n",
    "    return tag\n",
    "def process_sentence(sentence):\n",
    "    if isinstance(sentence, list):  # Check if 'sentence' is a list\n",
    "        sentence = [str(sent).lower() for sent in sentence]  # Convert to string and lowercase\n",
    "        sentence = [\"<s>\"] + sentence  # Add Start Token\n",
    "    return sentence\n",
    "def process_data(data_path):\n",
    "     df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "     df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    " \n",
    "     sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "     tags = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\n",
    " \n",
    "     sentences = [process_sentence(sentence) for sentence in sentences]\n",
    "     tags = [process_tag(tag) for tag in tags]\n",
    " \n",
    "     return sentences, tags\n",
    "data_path = r\"D:\\Malathi\\SEM_6\\NLP\\archive\\NER dataset.csv\"\n",
    "sentences, tags = process_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ac774",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60623b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tags : 10\n",
      "Tags : ['org', 'nat', 'per', 'gpe', 'O', 'geo', 'tim', 'art', 'eve', '<s>']\n"
     ]
    }
   ],
   "source": [
    "# No of Tags\n",
    "# <s> - Start Token\n",
    "tag = set()\n",
    "for t in tags:\n",
    " tag.update(set(t))\n",
    " \n",
    "print(\"Number of Tags :\", len(tag))\n",
    "print(\"Tags :\", list(tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d492fd",
   "metadata": {},
   "source": [
    "### Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d0efd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org</th>\n",
       "      <th>nat</th>\n",
       "      <th>per</th>\n",
       "      <th>gpe</th>\n",
       "      <th>O</th>\n",
       "      <th>geo</th>\n",
       "      <th>tim</th>\n",
       "      <th>art</th>\n",
       "      <th>eve</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>0.454641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.513422</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per</th>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.504017</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.470184</td>\n",
       "      <td>0.006895</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpe</th>\n",
       "      <td>0.026516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081601</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.869040</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.019595</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.889694</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.807015</td>\n",
       "      <td>0.164686</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tim</th>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.745251</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.243128</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548711</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>0.425501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.057382</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.083801</td>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.715403</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          org       nat       per       gpe         O       geo       tim  \\\n",
       "org  0.454641  0.000000  0.017661  0.004036  0.513422  0.001192  0.008776   \n",
       "nat  0.000000  0.202381  0.007937  0.000000  0.781746  0.003968  0.003968   \n",
       "per  0.011132  0.000058  0.504017  0.001870  0.470184  0.006895  0.005843   \n",
       "gpe  0.026516  0.000000  0.081601  0.012324  0.869040  0.008465  0.001930   \n",
       "O    0.019595  0.000223  0.012882  0.014839  0.889694  0.040195  0.021812   \n",
       "geo  0.001533  0.000000  0.002888  0.003243  0.807015  0.164686  0.020525   \n",
       "tim  0.001937  0.000037  0.001899  0.002123  0.745251  0.004655  0.243128   \n",
       "art  0.004298  0.000000  0.005731  0.000000  0.548711  0.002865  0.012894   \n",
       "eve  0.000000  0.000000  0.000000  0.000000  0.537500  0.000000  0.010714   \n",
       "<s>  0.057382  0.000229  0.083801  0.062324  0.715403  0.069539  0.010738   \n",
       "\n",
       "          art       eve  <s>  \n",
       "org  0.000217  0.000054  0.0  \n",
       "nat  0.000000  0.000000  0.0  \n",
       "per  0.000000  0.000000  0.0  \n",
       "gpe  0.000062  0.000062  0.0  \n",
       "O    0.000437  0.000324  0.0  \n",
       "geo  0.000089  0.000022  0.0  \n",
       "tim  0.000149  0.000819  0.0  \n",
       "art  0.425501  0.000000  0.0  \n",
       "eve  0.000000  0.451786  0.0  \n",
       "<s>  0.000375  0.000209  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_transition_matrix(tags):\n",
    "    # Bigram\n",
    "    bigram = {}\n",
    "    for tag in tags:\n",
    "        for idx in range(len(tag)-1):\n",
    "            b_tuple = (tag[idx], tag[idx+1])\n",
    "            if(bigram.get(b_tuple, -1) == -1):\n",
    "                bigram[b_tuple] = 1\n",
    "            else:\n",
    "                bigram[b_tuple] += 1\n",
    " \n",
    "    # Tags \n",
    "    tag = set()\n",
    "    for t in tags:\n",
    "        tag.update(set(t))\n",
    "    no_tag = len(tag)\n",
    "    tag = list(tag)\n",
    " \n",
    "    # Transition Matrix\n",
    "    transition_matrix = pd.DataFrame(np.zeros((no_tag, no_tag)), index=tag, columns=tag)\n",
    " \n",
    "    # Populate Transition Matrix\n",
    "    for tag_first in tag:\n",
    "        for tag_second in tag:\n",
    "            transition_matrix[tag_first][tag_second] = bigram.get((tag_first, tag_second), 0)\n",
    " \n",
    "    transition_matrix = transition_matrix / transition_matrix.sum(axis=0)\n",
    " \n",
    "    return transition_matrix\n",
    " \n",
    "transition_matrix = create_transition_matrix(tags)\n",
    "transition_matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73887bb3",
   "metadata": {},
   "source": [
    "### Emission Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d14ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatim</th>\n",
       "      <th>83-year-old</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>invested</th>\n",
       "      <th>edging</th>\n",
       "      <th>aires</th>\n",
       "      <th>bodies</th>\n",
       "      <th>trick</th>\n",
       "      <th>yazidis</th>\n",
       "      <th>swim</th>\n",
       "      <th>...</th>\n",
       "      <th>insensible</th>\n",
       "      <th>airways</th>\n",
       "      <th>drug-combination</th>\n",
       "      <th>didier</th>\n",
       "      <th>lags</th>\n",
       "      <th>gongga</th>\n",
       "      <th>underfunding</th>\n",
       "      <th>khuzestan</th>\n",
       "      <th>upswing</th>\n",
       "      <th>doctorate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpe</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tim</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 31819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatim  83-year-old  sponsored  invested    edging     aires    bodies  \\\n",
       "org  0.000000     0.000000   0.000000  0.000000  0.000000  0.000081  0.000000   \n",
       "nat  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "per  0.000029     0.000000   0.000000  0.000000  0.000000  0.000029  0.000000   \n",
       "gpe  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "O    0.000000     0.000001   0.000017  0.000012  0.000001  0.000000  0.000189   \n",
       "geo  0.000000     0.000000   0.000000  0.000000  0.000000  0.000089  0.000000   \n",
       "tim  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "art  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "eve  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        trick   yazidis      swim  ...  insensible   airways  \\\n",
       "org  0.000000  0.000027  0.000000  ...    0.000000  0.000190   \n",
       "nat  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "per  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "gpe  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "O    0.000003  0.000000  0.000007  ...    0.000001  0.000000   \n",
       "geo  0.000000  0.000000  0.000000  ...    0.000000  0.000022   \n",
       "tim  0.000000  0.000000  0.000000  ...    0.000000  0.000037   \n",
       "art  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "eve  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "\n",
       "     drug-combination    didier      lags    gongga  underfunding  khuzestan  \\\n",
       "org          0.000000  0.000000  0.000000  0.000000      0.000000   0.000000   \n",
       "nat          0.000000  0.000000  0.000000  0.000000      0.000000   0.000000   \n",
       "per          0.000000  0.000088  0.000000  0.000000      0.000000   0.000000   \n",
       "gpe          0.000000  0.000000  0.000000  0.000000      0.000000   0.000000   \n",
       "O            0.000001  0.000000  0.000002  0.000000      0.000001   0.000000   \n",
       "geo          0.000000  0.000000  0.000000  0.000022      0.000000   0.000022   \n",
       "tim          0.000000  0.000000  0.000000  0.000000      0.000000   0.000000   \n",
       "art          0.000000  0.000000  0.000000  0.000000      0.000000   0.000000   \n",
       "eve          0.000000  0.000000  0.000000  0.000000      0.000000   0.000000   \n",
       "\n",
       "      upswing  doctorate  \n",
       "org  0.000000   0.000000  \n",
       "nat  0.000000   0.000000  \n",
       "per  0.000000   0.000000  \n",
       "gpe  0.000000   0.000000  \n",
       "O    0.000007   0.000003  \n",
       "geo  0.000000   0.000000  \n",
       "tim  0.000000   0.000000  \n",
       "art  0.000000   0.000000  \n",
       "eve  0.000000   0.000000  \n",
       "\n",
       "[9 rows x 31819 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_emission_matrix(sentences, tags):\n",
    "    # Vocab\n",
    "    vocab = set()\n",
    "    for s in sentences:\n",
    "         vocab.update(set(s))\n",
    "    no_vocab = len(vocab)\n",
    "    vocab = list(vocab)\n",
    " \n",
    "    # Tags\n",
    "    tag = set()\n",
    "    for t in tags:\n",
    "        tag.update(set(t))\n",
    "    tag = list(tag)\n",
    "    tag.remove(\"<s>\")\n",
    "    no_tag = len(tag)\n",
    " \n",
    "    # Emission Matrix\n",
    "    emission_matrix = pd.DataFrame(np.zeros((no_vocab, no_tag)), index=vocab, columns=tag)\n",
    " \n",
    "    # Populate Transition Matrix\n",
    "    no = len(sentences)\n",
    "    pair = {}\n",
    " \n",
    "    for i in range(no):\n",
    "        for idx in range(len(sentences[i])):\n",
    "            t = tags[i][idx]\n",
    "            v = sentences[i][idx]\n",
    "            if(pair.get((t, v), -1) == -1):\n",
    "                pair[(t, v)] = 1\n",
    "            else:\n",
    "                 pair[(t, v)] += 1\n",
    " \n",
    "    for (t, v), val in pair.items():\n",
    "        if(t == \"<s>\"):\n",
    "            continue\n",
    "        emission_matrix[t][v] = val\n",
    " \n",
    "    emission_matrix = emission_matrix / emission_matrix.sum(axis=0)\n",
    " \n",
    "    return emission_matrix\n",
    "emission_matrix = create_emission_matrix(sentences, tags)\n",
    "emission_matrix.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2822104",
   "metadata": {},
   "source": [
    "### Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f869a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbo_algorithm(transition_matrix, emission_matrix, sent):\n",
    "    start_tok = \"<s>\"\n",
    "    tags = list(emission_matrix.columns)\n",
    "    matrix = pd.DataFrame(np.zeros((len(tags), len(sent))), index=tags)\n",
    "    trace_back = pd.DataFrame(np.full((len(tags), len(sent)), -1), index = tags)\n",
    " \n",
    "    result = [0] * len(sent)\n",
    " \n",
    "    # Initial Prob\n",
    "    for t in tags:\n",
    "        word = sent[0]\n",
    "        matrix[0][t] = transition_matrix[start_tok][t] * emission_matrix[t][word]\n",
    " \n",
    "    # Forward Pass \n",
    "    for idx in range(1, len(sent)):\n",
    "        prev_idx = idx - 1\n",
    "        word = sent[idx]\n",
    " \n",
    "        for tag in tags:\n",
    "            possible_path = []\n",
    "            for t in tags:\n",
    "                possible_path.append(matrix[prev_idx][t] * transition_matrix[t][tag] * emission_matrix[tag][word])\n",
    "            matrix[idx][tag] = max(possible_path)\n",
    "            trace_back[idx][tag] = np.argmax(possible_path)\n",
    " \n",
    "    # Backward Pass\n",
    "    idx = len(sent) - 1\n",
    "    last_idx = np.argmax(matrix[idx])\n",
    " \n",
    "    while(last_idx != -1):\n",
    "        result[idx] = tags[last_idx]\n",
    "        last_idx = trace_back[idx][tags[last_idx]]\n",
    "        idx -= 1\n",
    " \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9726316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpe', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbo_algorithm(transition_matrix, emission_matrix, [\"indian\", \"women\", \"team\", \"is\",\"great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362ba43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (speed)",
   "language": "python",
   "name": "speed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
